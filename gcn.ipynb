{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#codebase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data,HeteroData\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv,HeteroConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c001d4cf1f7617b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T08:24:31.658845Z",
     "start_time": "2025-04-14T08:24:22.770509Z"
    }
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb5685cb0735c65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T08:24:43.790329Z",
     "start_time": "2025-04-14T08:24:43.774277Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "    # 对 userId 和 movieId 重新编码为从 0 开始的连续整数\n",
    "    df = df.copy()\n",
    "    df['userId'] = df['userId'].astype('category').cat.codes\n",
    "    df['movieId'] = df['movieId'].astype('category').cat.codes\n",
    "\n",
    "    num_users = df['userId'].nunique()\n",
    "    num_movies = df['movieId'].nunique()\n",
    "    graph = HeteroData()\n",
    "    \n",
    "    # 确保 user.x 和 movie.x 的维度足够大\n",
    "    graph['user'].x = torch.arange(num_users, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "    merged_df = pd.merge(df,movies,how='left',on='movieId')\n",
    "    merged_df = merged_df[['movieId','genres']].drop_duplicates()\n",
    "    genres = merged_df['genres'].str.get_dummies(sep='|')\n",
    "    item_features = torch.tensor(genres.values, dtype=torch.float)\n",
    "    graph['movie'].x = item_features\n",
    "    \n",
    "    # 检查 edge_index 的索引范围\n",
    "    edge_index = torch.tensor([df['userId'].values, df['movieId'].values], dtype=torch.long)\n",
    "    \n",
    "    assert edge_index[0].max() < num_users, \"User ID 越界\"\n",
    "    assert edge_index[1].max() < num_movies, \"Movie ID 越界\"\n",
    "    \n",
    "    graph['user', 'rates', 'movie'].edge_index = edge_index\n",
    "    graph['user', 'rates', 'movie'].edge_attr = torch.tensor(df['rating'].values, dtype=torch.float) \n",
    "    graph['movie', 'rated_by', 'user'].edge_index = edge_index[[1, 0]]  # 更安全的翻转方式\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56ad4d8d875e0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:29:12.336655Z",
     "start_time": "2025-04-14T06:29:05.570049Z"
    }
   },
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67625814825aa4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T08:25:44.166295Z",
     "start_time": "2025-04-14T08:25:20.155904Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78529\\AppData\\Local\\Temp\\ipykernel_19512\\1530743362.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  edge_index = torch.tensor([df['userId'].values, df['movieId'].values], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "train_graph = create_graph(train_ratings).to(device)\n",
    "test_graph = create_graph(test_ratings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec114e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[200948, 1] },\n",
       "  movie={ x=[80318, 19] },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 25600163],\n",
       "    edge_attr=[25600163],\n",
       "  },\n",
       "  (movie, rated_by, user)={ edge_index=[2, 25600163] }\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f2b7496ca1dfa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T08:26:50.323216Z",
     "start_time": "2025-04-14T08:26:50.262300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户节点数: 200948\n",
      "电影节点数: 80318\n",
      "边索引最大值 - user: 200947\n",
      "边索引最大值 - movie: 80317\n"
     ]
    }
   ],
   "source": [
    "print(\"用户节点数:\", train_graph['user'].x.shape[0])\n",
    "print(\"电影节点数:\", train_graph['movie'].x.shape[0])\n",
    "print(\"边索引最大值 - user:\", train_graph['user', 'rates', 'movie'].edge_index[0].max().item())\n",
    "print(\"边索引最大值 - movie:\", train_graph['user', 'rates', 'movie'].edge_index[1].max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6efcdf92e0f01b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T08:27:27.591363Z",
     "start_time": "2025-04-14T08:27:27.578253Z"
    }
   },
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin_dict = torch.nn.ModuleDict({\n",
    "            'user': torch.nn.LazyLinear(hidden_channels),\n",
    "            'movie': torch.nn.LazyLinear(hidden_channels)\n",
    "        })\n",
    "        \n",
    "        self.norm_dict = torch.nn.ModuleDict({\n",
    "            'user': torch.nn.BatchNorm1d(hidden_channels),\n",
    "            'movie': torch.nn.BatchNorm1d(hidden_channels)\n",
    "        })\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'rates', 'movie'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('movie', 'rated_by', 'user'): SAGEConv((-1, -1), hidden_channels),\n",
    "        }, aggr='mean')\n",
    "        \n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'rates', 'movie'): SAGEConv((-1, -1), out_channels),\n",
    "            ('movie', 'rated_by', 'user'): SAGEConv((-1, -1), out_channels),\n",
    "        }, aggr='mean')\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # 特征变换\n",
    "        x_dict = {key: self.lin_dict[key](x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: self.norm_dict[key](x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: self.dropout(F.relu(x)) for key, x in x_dict.items()}\n",
    "        \n",
    "        # 图卷积\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: self.dropout(F.relu(x)) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        \n",
    "        return x_dict\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * hidden_channels, 4 * hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(4 * hidden_channels, 2 * hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2 * hidden_channels, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        user_z = z_dict['user'][edge_label_index[0]]\n",
    "        movie_z = z_dict['movie'][edge_label_index[1]]\n",
    "        features = torch.cat([user_z, movie_z], dim=-1)\n",
    "        return self.mlp(features).squeeze(-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, metadata):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e0855974757f208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T08:27:33.671351Z",
     "start_time": "2025-04-14T08:27:33.557311Z"
    }
   },
   "outputs": [],
   "source": [
    "user_feat_dim = train_graph['user'].x.size(1)\n",
    "movie_feat_dim = train_graph['movie'].x.size(1)\n",
    "\n",
    "model = Model(hidden_channels=64, metadata=train_graph.metadata()).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eeb9640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "def prepare_loaders(train_graph, test_graph, batch_size=512):\n",
    "    # 训练加载器 - 包含评分作为边属性\n",
    "    train_loader = LinkNeighborLoader(\n",
    "        data=train_graph,\n",
    "        num_neighbors=[20, 10],  # 采样邻居数\n",
    "        edge_label_index=(('user', 'rates', 'movie'), train_graph[('user', 'rates', 'movie')].edge_index),\n",
    "        edge_label=train_graph[('user', 'rates', 'movie')].edge_attr,  # 使用实际评分\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    # 测试加载器\n",
    "    test_loader = LinkNeighborLoader(\n",
    "        data=test_graph,\n",
    "        num_neighbors=[20, 10],\n",
    "        edge_label_index=(('user', 'rates', 'movie'), test_graph[('user', 'rates', 'movie')].edge_index),\n",
    "        edge_label=test_graph[('user', 'rates', 'movie')].edge_attr,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5c2d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = prepare_loaders(train_graph, test_graph, batch_size=4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e01b672be8c1ea64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T08:27:48.765351Z",
     "start_time": "2025-04-14T08:27:38.963452Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(batch.x_dict, batch.edge_index_dict, \n",
    "                    batch[('user', 'rates', 'movie')].edge_label_index)\n",
    "        \n",
    "        # 使用均方误差损失\n",
    "        loss = F.mse_loss(pred, batch[('user', 'rates', 'movie')].edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.size(0)\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_mse = 0\n",
    "    total_mae = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch.x_dict, batch.edge_index_dict,\n",
    "                        batch[('user', 'rates', 'movie')].edge_label_index)\n",
    "            \n",
    "            mse = F.mse_loss(pred, batch[('user', 'rates', 'movie')].edge_label)\n",
    "            mae = F.l1_loss(pred, batch[('user', 'rates', 'movie')].edge_label)\n",
    "            \n",
    "            total_mse += float(mse) * pred.size(0)\n",
    "            total_mae += float(mae) * pred.size(0)\n",
    "    \n",
    "    return {\n",
    "        'mse': total_mse / len(loader.dataset),\n",
    "        'mae': total_mae / len(loader.dataset),\n",
    "        'rmse': np.sqrt(total_mse / len(loader.dataset))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67323e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[161934,  23151, 152930,  ..., 100886, 145265, 198409],\n",
       "        [  2233,  28513,   4252,  ...,  64923,  10397,   5241]],\n",
       "       device='cuda:0'), 'edge_attr': tensor([5.0000, 5.0000, 4.5000,  ..., 3.5000, 3.0000, 2.5000], device='cuda:0')}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph[('user', 'rates', 'movie')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0480f930398f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(model, data, user_id, top_k=10, device='cpu'):\n",
    "    \"\"\"\n",
    "    为指定用户生成电影推荐\n",
    "    \n",
    "    参数:\n",
    "        model: 训练好的推荐模型\n",
    "        data: 包含图数据的HeteroData对象\n",
    "        user_id: 要推荐的用户ID(原始ID或编码后ID)\n",
    "        top_k: 返回的推荐数量\n",
    "        device: 计算设备('cpu'或'cuda')\n",
    "    \n",
    "    返回:\n",
    "        tuple: (推荐电影ID列表, 预测评分列表)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 获取所有节点表示\n",
    "        z_dict = model.encoder(data.x_dict, data.edge_index_dict)\n",
    "        \n",
    "        # 确保user_id是tensor格式\n",
    "        if isinstance(user_id, int):\n",
    "            user_id = torch.tensor([user_id], device=device)\n",
    "        \n",
    "        # 获取目标用户表示\n",
    "        user_emb = z_dict['user'][user_id]  # shape: [1, emb_dim]\n",
    "        movie_emb = z_dict['movie']         # shape: [num_movies, emb_dim]\n",
    "        \n",
    "        # 计算用户对所有电影的预测分数 (使用解码器)\n",
    "        edge_label_index = torch.stack([\n",
    "            user_id.repeat(movie_emb.size(0)),\n",
    "            torch.arange(movie_emb.size(0), device=device)\n",
    "        ])\n",
    "        scores = model.decoder(z_dict, edge_label_index)  # shape: [num_movies]\n",
    "        \n",
    "        # 排除已评分的电影\n",
    "        rated_mask = torch.zeros(movie_emb.size(0), dtype=torch.bool, device=device)\n",
    "        user_edges = (data['user', 'rates', 'movie'].edge_index[0] == user_id)\n",
    "        rated_movies = data['user', 'rates', 'movie'].edge_index[1][user_edges]\n",
    "        rated_mask[rated_movies] = True\n",
    "        scores[rated_mask] = -float('inf')\n",
    "        \n",
    "        # 获取top-k推荐及其分数\n",
    "        top_scores, top_movies = torch.topk(scores, k=min(top_k, len(scores)))\n",
    "        \n",
    "        return top_movies.cpu().numpy(), top_scores.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fad2654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 训练循环\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, device)\n\u001b[0;32m      8\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(epoch)\n",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      6\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\loader\\base.py:39\u001b[0m, in \u001b[0;36mDataLoaderIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_fn(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\loader\\link_loader.py:211\u001b[0m, in \u001b[0;36mLinkLoader.collate_fn\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Samples a subgraph from a batch of input edges.\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m input_data: EdgeSamplerInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data[index]\n\u001b[1;32m--> 211\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_edges\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_sampling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_per_worker:  \u001b[38;5;66;03m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:334\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_edges\u001b[1;34m(self, inputs, neg_sampling)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_from_edges\u001b[39m(\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    331\u001b[0m     inputs: EdgeSamplerInput,\n\u001b[0;32m    332\u001b[0m     neg_sampling: Optional[NegativeSampling] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[1;32m--> 334\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43medge_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisjoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_sampling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubgraph_type \u001b[38;5;241m==\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39mbidirectional:\n\u001b[0;32m    337\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto_bidirectional()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:666\u001b[0m, in \u001b[0;36medge_sample\u001b[1;34m(inputs, sample_fn, num_nodes, disjoint, node_time, neg_sampling)\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m edge_label_time \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Always disjoint.\u001b[39;00m\n\u001b[0;32m    662\u001b[0m         seed_time_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    663\u001b[0m             input_type[\u001b[38;5;241m0\u001b[39m]: torch\u001b[38;5;241m.\u001b[39mcat([src_time, dst_time], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    664\u001b[0m         }\n\u001b[1;32m--> 666\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_time_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# Enhance `out` by label information ##################################\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disjoint:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:390\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[1;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[0;32m    379\u001b[0m     args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_weight, )\n\u001b[0;32m    380\u001b[0m args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# csc\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# return_edge_id\u001b[39;00m\n\u001b[0;32m    388\u001b[0m )\n\u001b[1;32m--> 390\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhetero_neighbor_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m row, col, node, edge, batch \u001b[38;5;241m=\u001b[39m out[:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# `pyg-lib>0.1.0` returns sampled number of nodes/edges:\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练循环\n",
    "print(\"开始训练...\")\n",
    "# 训练循环\n",
    "for epoch in range(1, 6):\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    test_metrics = evaluate(model, test_loader, device)\n",
    "    \n",
    "    scheduler.step(epoch)\n",
    "    \n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, '\n",
    "          f'Test RMSE: {test_metrics[\"rmse\"]:.4f}, MAE: {test_metrics[\"mae\"]:.4f}')\n",
    "    \n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'movie_recommender.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1918d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例推荐\n",
    "user_id = 0  # 选择第一个用户\n",
    "recommended_movies = generate_recommendations(model, train_graph, user_id)\n",
    "movie_titles = movies.set_index('movieId')['title'].to_dict()\n",
    "print(f\"\\n为用户 {user_id} 推荐的电影:\")\n",
    "for i, movie_id in enumerate(recommended_movies, 1):\n",
    "    original_id = train_graph['movieId'].unique()[movie_id]\n",
    "    print(f\"{i}. {movie_titles.get(original_id, '未知电影')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
